{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Data - I\n",
    "\n",
    "\n",
    "There are multiple ways of getting data into python, depending on where the data is stored. The simplest case is when you have data in CSV files, but often, you need to get data from other formats, sources and documents, such as text files, relational databases, websites, APIs, PDF documents, etc. \n",
    "\n",
    "In the following sections, you will learn to get data into python from a number of sources. You will learn to:\n",
    "* Get data from text files\n",
    "* Get data from relational databases\n",
    "* Scrape data from websites\n",
    "* Get data from publicly available APIs\n",
    "* Read PDFs into python\n",
    "\n",
    "In the process, you will also learn how to deal with nuances that inevitably come while getting data from various sources.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Delimited Files\n",
    "\n",
    "Delimited files are usually text files, where columns are separated by delimiters (such as commas, tabs, semicolons etc.) and each new line is a row.\n",
    "\n",
    "For instance, we have the ```companies.txt``` file, where each column is separated by a tab:\n",
    "\n",
    "<img src=\"companies.png\" style=\"height: 500px; width: 600px\">\n",
    "\n",
    "The easiest way to read delimited files is using ```pd.read_csv(filepath, sep, header)``` and specify a separator (delimiter).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# reading companies file: throws an error\n",
    "# companies = pd.read_csv(\"companies.txt\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error appears because of a decoding issue pandas is facing. The best way to resolve such problems to search for help, for example on stack overflow, where you'd get excellent suggestions from the community.\n",
    "\n",
    "One possible solution to this problem is found here: https://stackoverflow.com/questions/18171739/unicodedecodeerror-when-reading-csv-file-in-pandas-with-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>permalink</th>\n",
       "      <th>name</th>\n",
       "      <th>homepage_url</th>\n",
       "      <th>category_list</th>\n",
       "      <th>status</th>\n",
       "      <th>country_code</th>\n",
       "      <th>state_code</th>\n",
       "      <th>region</th>\n",
       "      <th>city</th>\n",
       "      <th>founded_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Organization/-Fame</td>\n",
       "      <td>#fame</td>\n",
       "      <td>http://livfame.com</td>\n",
       "      <td>Media</td>\n",
       "      <td>operating</td>\n",
       "      <td>IND</td>\n",
       "      <td>16</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Organization/-Qounter</td>\n",
       "      <td>:Qounter</td>\n",
       "      <td>http://www.qounter.com</td>\n",
       "      <td>Application Platforms|Real Time|Social Network...</td>\n",
       "      <td>operating</td>\n",
       "      <td>USA</td>\n",
       "      <td>DE</td>\n",
       "      <td>DE - Other</td>\n",
       "      <td>Delaware City</td>\n",
       "      <td>04-09-2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Organization/-The-One-Of-Them-Inc-</td>\n",
       "      <td>(THE) ONE of THEM,Inc.</td>\n",
       "      <td>http://oneofthem.jp</td>\n",
       "      <td>Apps|Games|Mobile</td>\n",
       "      <td>operating</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Organization/0-6-Com</td>\n",
       "      <td>0-6.com</td>\n",
       "      <td>http://www.0-6.com</td>\n",
       "      <td>Curated Web</td>\n",
       "      <td>operating</td>\n",
       "      <td>CHN</td>\n",
       "      <td>22</td>\n",
       "      <td>Beijing</td>\n",
       "      <td>Beijing</td>\n",
       "      <td>01-01-2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Organization/004-Technologies</td>\n",
       "      <td>004 Technologies</td>\n",
       "      <td>http://004gmbh.de/en/004-interact</td>\n",
       "      <td>Software</td>\n",
       "      <td>operating</td>\n",
       "      <td>USA</td>\n",
       "      <td>IL</td>\n",
       "      <td>Springfield, Illinois</td>\n",
       "      <td>Champaign</td>\n",
       "      <td>01-01-2010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             permalink                    name  \\\n",
       "0                  /Organization/-Fame                   #fame   \n",
       "1               /Organization/-Qounter                :Qounter   \n",
       "2  /Organization/-The-One-Of-Them-Inc-  (THE) ONE of THEM,Inc.   \n",
       "3                /Organization/0-6-Com                 0-6.com   \n",
       "4       /Organization/004-Technologies        004 Technologies   \n",
       "\n",
       "                        homepage_url  \\\n",
       "0                 http://livfame.com   \n",
       "1             http://www.qounter.com   \n",
       "2                http://oneofthem.jp   \n",
       "3                 http://www.0-6.com   \n",
       "4  http://004gmbh.de/en/004-interact   \n",
       "\n",
       "                                       category_list     status country_code  \\\n",
       "0                                              Media  operating          IND   \n",
       "1  Application Platforms|Real Time|Social Network...  operating          USA   \n",
       "2                                  Apps|Games|Mobile  operating          NaN   \n",
       "3                                        Curated Web  operating          CHN   \n",
       "4                                           Software  operating          USA   \n",
       "\n",
       "  state_code                 region           city  founded_at  \n",
       "0         16                 Mumbai         Mumbai         NaN  \n",
       "1         DE             DE - Other  Delaware City  04-09-2014  \n",
       "2        NaN                    NaN            NaN         NaN  \n",
       "3         22                Beijing        Beijing  01-01-2007  \n",
       "4         IL  Springfield, Illinois      Champaign  01-01-2010  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using encoding = \"ISO-8859-1\"\n",
    "companies = pd.read_csv(\"companies.txt\", sep=\"\\t\" ,encoding = \"ISO-8859-1\")\n",
    "companies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Data From Relational Databases\n",
    "\n",
    "Data is commonly stored in RDBMS, and it is easy to get it into Python. We'll use the most common one - MySQL.\n",
    "\n",
    "There are many libraries to connect MySQL and Python, such as pymysql, MySQLdb, etc. All of them follow the following procedure to connect to MySQL:\n",
    "- Create a connection object between MySQL and python\n",
    "- Create a cursor object (you use the cursor to open and close the connection) \n",
    "- Execute the SQL query \n",
    "- Retrive results of the query using methods such as ```fetchone()```, ```fetchall()```, etc.\n",
    "\n",
    "Let' work through an example using PyMySQL. You can install it using ```pip install pymysql```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "(1045, \"Access denied for user 'root'@'localhost' (using password: YES)\")",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpymysql\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# create a connection object 'conn'\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m conn \u001b[38;5;241m=\u001b[39m \u001b[43mpymysql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlocalhost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# your host, localhost for your local machine\u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m \u001b[43m                     \u001b[49m\u001b[43muser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mroot\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# your username, usually \"root\" for localhost\u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mpasswd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43myourpassword\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# your password\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mdb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mworld\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# name of the data base; world comes inbuilt with mysql\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# create a cursor object c\u001b[39;00m\n\u001b[1;32m     10\u001b[0m c \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mcursor()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pymysql/connections.py:358\u001b[0m, in \u001b[0;36mConnection.__init__\u001b[0;34m(self, user, password, host, database, unix_socket, port, charset, collation, sql_mode, read_default_file, conv, use_unicode, client_flag, cursorclass, init_command, connect_timeout, read_default_group, autocommit, local_infile, max_allowed_packet, defer_connect, auth_plugin_map, read_timeout, write_timeout, bind_address, binary_prefix, program_name, server_public_key, ssl, ssl_ca, ssl_cert, ssl_disabled, ssl_key, ssl_verify_cert, ssl_verify_identity, compress, named_pipe, passwd, db)\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 358\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pymysql/connections.py:664\u001b[0m, in \u001b[0;36mConnection.connect\u001b[0;34m(self, sock)\u001b[0m\n\u001b[1;32m    661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_seq_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    663\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_server_information()\n\u001b[0;32m--> 664\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request_authentication\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    666\u001b[0m \u001b[38;5;66;03m# Send \"SET NAMES\" query on init for:\u001b[39;00m\n\u001b[1;32m    667\u001b[0m \u001b[38;5;66;03m# - Ensure charaset (and collation) is set to the server.\u001b[39;00m\n\u001b[1;32m    668\u001b[0m \u001b[38;5;66;03m#   - collation_id in handshake packet may be ignored.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[38;5;66;03m# - https://github.com/wagtail/wagtail/issues/9477\u001b[39;00m\n\u001b[1;32m    678\u001b[0m \u001b[38;5;66;03m# - https://zenn.dev/methane/articles/2023-mysql-collation (Japanese)\u001b[39;00m\n\u001b[1;32m    679\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_character_set(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcharset, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcollation)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pymysql/connections.py:976\u001b[0m, in \u001b[0;36mConnection._request_authentication\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    974\u001b[0m \u001b[38;5;66;03m# https://dev.mysql.com/doc/internals/en/successful-authentication.html\u001b[39;00m\n\u001b[1;32m    975\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_auth_plugin_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcaching_sha2_password\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 976\u001b[0m     auth_packet \u001b[38;5;241m=\u001b[39m \u001b[43m_auth\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaching_sha2_password_auth\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth_packet\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_auth_plugin_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msha256_password\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    978\u001b[0m     auth_packet \u001b[38;5;241m=\u001b[39m _auth\u001b[38;5;241m.\u001b[39msha256_password_auth(\u001b[38;5;28mself\u001b[39m, auth_packet)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pymysql/_auth.py:267\u001b[0m, in \u001b[0;36mcaching_sha2_password_auth\u001b[0;34m(conn, pkt)\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[38;5;28mprint\u001b[39m(conn\u001b[38;5;241m.\u001b[39mserver_public_key\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mascii\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m    266\u001b[0m data \u001b[38;5;241m=\u001b[39m sha2_rsa_encrypt(conn\u001b[38;5;241m.\u001b[39mpassword, conn\u001b[38;5;241m.\u001b[39msalt, conn\u001b[38;5;241m.\u001b[39mserver_public_key)\n\u001b[0;32m--> 267\u001b[0m pkt \u001b[38;5;241m=\u001b[39m \u001b[43m_roundtrip\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pymysql/_auth.py:120\u001b[0m, in \u001b[0;36m_roundtrip\u001b[0;34m(conn, send_data)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_roundtrip\u001b[39m(conn, send_data):\n\u001b[1;32m    119\u001b[0m     conn\u001b[38;5;241m.\u001b[39mwrite_packet(send_data)\n\u001b[0;32m--> 120\u001b[0m     pkt \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_packet\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m     pkt\u001b[38;5;241m.\u001b[39mcheck_error()\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pkt\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pymysql/connections.py:772\u001b[0m, in \u001b[0;36mConnection._read_packet\u001b[0;34m(self, packet_type)\u001b[0m\n\u001b[1;32m    770\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\u001b[38;5;241m.\u001b[39munbuffered_active \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    771\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\u001b[38;5;241m.\u001b[39munbuffered_active \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 772\u001b[0m     \u001b[43mpacket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    773\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m packet\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pymysql/protocol.py:221\u001b[0m, in \u001b[0;36mMysqlPacket.raise_for_error\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m DEBUG:\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merrno =\u001b[39m\u001b[38;5;124m\"\u001b[39m, errno)\n\u001b[0;32m--> 221\u001b[0m \u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_mysql_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pymysql/err.py:143\u001b[0m, in \u001b[0;36mraise_mysql_exception\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m errorclass \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    142\u001b[0m     errorclass \u001b[38;5;241m=\u001b[39m InternalError \u001b[38;5;28;01mif\u001b[39;00m errno \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1000\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m OperationalError\n\u001b[0;32m--> 143\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m errorclass(errno, errval)\n",
      "\u001b[0;31mOperationalError\u001b[0m: (1045, \"Access denied for user 'root'@'localhost' (using password: YES)\")"
     ]
    }
   ],
   "source": [
    "import pymysql\n",
    "\n",
    "# create a connection object 'conn'\n",
    "conn = pymysql.connect(host=\"Manojs-MacBook-Pro.local\", # your host, localhost for your local machine\n",
    "                     user=\"root\", # your username, usually \"root\" for localhost\n",
    "                      passwd=\"yourpassword\", # your password\n",
    "                      db=\"world\") # name of the data base; world comes inbuilt with mysql\n",
    "\n",
    "# create a cursor object c\n",
    "c = conn.cursor()\n",
    "\n",
    "# execute a query using c.execute\n",
    "c.execute(\"select * from city;\")\n",
    "\n",
    "# getting the first row of data as a tuple\n",
    "all_rows = c.fetchall()\n",
    "\n",
    "# to get only the first row, use c.fetchone() instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notice that it returns a tuple of tuples: each row is a tuple\n",
    "print(type(all_rows))\n",
    "\n",
    "# printing the first few rows\n",
    "print(all_rows[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, it would be useful to convert the list into a dataframe, since you can now work with dataframes easily. In this case, you can use the ```pd.DataFrame()``` function, and pass the list version of the tuple.\n",
    "\n",
    "```pd.DataFrame(list_of_tuples)``` converts each tuple in the list to a row in the DF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(all_rows), columns=[\"ID\", \"Name\", \"Country\", \"District\", \"Population\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Data From Websites\n",
    "\n",
    "Web scraping refers to the art of programmatically getting data from the internet.  One of the coolest features of python is that it makes it easy to scrape websites.\n",
    "\n",
    "In Python 3, the most popular library for web scraping is ```BeautifulSoup```. To use ```BeautifulSoup```, we will also need the ```requests``` module, which basically connects to a given URL and fetches data from it (in HTML format). A web page is basically HTML code, and the main use of ```BeautifulSoup``` is that it helps you parse HTML easily. \n",
    "\n",
    "**Note**: Discussion on HTML syntax is beyond the scope of this module, though even very basic HTML experience should be enough to understand web scraping. \n",
    "\n",
    "#### Use Case - Fetching Mobile App Reviews from Google Playstore\n",
    "\n",
    "Let's say you want to understand why people install and uninstall mobile apps, and why they like or dislike certain apps. A very rich source of app-reviews data is the Google Playstore, where people write their feedback about the app. \n",
    "\n",
    "The reviews of the Facebook messenger app can be found here: https://play.google.com/store/apps/details?id=com.facebook.orca&hl=en\n",
    "\n",
    "We will scrape reviews of the Messenger app, i.e. get them into python, and then you can do some interesting analyses on that.\n",
    "\n",
    "\n",
    "#### Parsing HTML Data using  BeautifulSoup and Requests\n",
    "\n",
    "To start using BeautifulSoup, install it using ```pip install beautifulsoup4```, and load the module bs4 using ```import bs4```. Also, install the requests module using ```pip install requests```.\n",
    "\n",
    "The general procedure to get data from websites is:\n",
    "1. Use ```requests``` to connect to a URL and get data from it\n",
    "2. Create a ```BeautifulSoup``` object \n",
    "3. Get attributes of the ```BeautifulSoup``` object (i.e. the HTML elements that you want)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, bs4\n",
    "\n",
    "# getting HTML from the Google Play web page\n",
    "url = \"https://play.google.com/store/apps/details?id=com.facebook.orca&hl=en\"\n",
    "req = requests.get(url)\n",
    "\n",
    "# create a bs4 object\n",
    "# To avoid warnings, provide \"html5lib\" explicitly\n",
    "soup = bs4.BeautifulSoup(req.text, \"html5lib\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have a bs4 object, you can use it to get specific parts of the HTML document. \n",
    "\n",
    "In HTML, the most common elements are either a part of a ```class```, or are assigned an ```id```. A typical HTML code looks like this:\n",
    "\n",
    "\n",
    "```\n",
    "    <body>\n",
    "        <div class=\"some_class\">\n",
    "            <p id=\"a_unique_id\">\n",
    "                A paragraph that you can read on the webpage here.\n",
    "            </p>\n",
    "        </div>\n",
    "    </body>\n",
    "```\n",
    "\n",
    "\n",
    "The easiest way to get specific parts of the webpage is using the ```soup.select()``` method of bs4. For e.g.:\n",
    "- ```soup.select('div')``` selects all the elements inside a 'div' tag\n",
    "- ```soup.select('div > p')``` selects all the ```<p>``` elements within div tags\n",
    "- ```soup.select('.some_class')``` selects elements inside  ```class = \"some_class\"```\n",
    "- ```soup.select('#some_id')``` selects all the elements inside the ```id=\"some_id\"``` element \n",
    "\n",
    "\n",
    "Now, you need to find the ids / classes / divs etc. inside which the reviews are located. To find those, go to the webpage, right click, and choose 'Inspect'. It will open up the HTML code.\n",
    "\n",
    "We'll not go into details, but if you look carefully, all the reviews are located inside a ```<div class=\"review-body\"> ```. So we use that class to fetch the reviews.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bs4.element.ResultSet'>\n",
      "0\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# printing an element of the reviews list\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mreviews\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m]\u001b[49m)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# getting all the text inside class = \"review-body\"\n",
    "reviews = soup.select('.review-body')\n",
    "print(type(reviews))\n",
    "print(len(reviews))\n",
    "print(\"\\n\")\n",
    "\n",
    "# printing an element of the reviews list\n",
    "print(reviews[6])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Notice that ```reviews``` is a list, and each element of the list contains some HTML code + the review string that we want.\n",
    "\n",
    "We still need to subset only the actual review string, and ignore all the other HTML, as shown in the highlighted section below (we want the bold string).\n",
    "\n",
    "```<div class=\"review-body with-review-wrapper\"> <span class=\"review-title\"></span>```\n",
    "**I love this app for it has many features but this is stressing me out bc it eats a lot of space and im only using samsung which is definitely cheap in giving internal storage. I have a lot of needs also, optimize the space of messenger. Thankyou. :) ily ppl who developed this. ** \n",
    "```<div class=\"review-link\" style=\"display:none\"> <a class=\"id-no-nav play-button tiny\" href=\"#\" target=\"_blank\"> Full Review </a> </div> </div>```\n",
    "\n",
    "\n",
    "Now, there are more than one ways to so this. One way is to ```str.split()``` the entire string into two parts using ```</span>``` as the separator (```str.split(\"sep\")``` separates a string into two parts at \"sep\").\n",
    "\n",
    "Then we'll get this:\n",
    "\n",
    "**I love this app for it has many features but this is stressing me out bc it eats a lot of space and im only using samsung which is definitely cheap in giving internal storage. I have a lot of needs also, optimize the space of messenger. Thankyou. :) ily ppl who developed this. ** \n",
    "```<div class=\"review-link\" style=\"display:none\"> <a class=\"id-no-nav play-button tiny\" href=\"#\" target=\"_blank\"> Full Review </a> </div> </div>```\n",
    "\n",
    "And then ```str.split()``` this string again using ```<div class=\"review-link'``` as the separator, so we'll get only the review string, i.e.:\n",
    "\n",
    "**I love this app for it has many features but this is stressing me out bc it eats a lot of space and im only using samsung which is definitely cheap in giving internal storage. I have a lot of needs also, optimize the space of messenger. Thankyou. :) ily ppl who developed this. ** \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1: split using </span>\n",
    "r = reviews[6]\n",
    "print(type(r))\n",
    "\n",
    "# r is a bs4 tag, convert it into string to use str.split() \n",
    "part1 = str(r).split(\"</span>\")\n",
    "print(part1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now split part1 using '<div class=\"review-link' as the separator\n",
    "# and get the first element of the resulting list\n",
    "# we get the review\n",
    "part2 = part1[1].split('<div class=\"review-link')[0]\n",
    "part2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So after applying ```str.split()``` twice, we get the review string.  Now, we simply apply this sequence of splitting to every element of the ```reviews``` list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply this sequence of splitting to every element of the reviews list\n",
    "# using a list comprehension\n",
    "reviews_text = [str(r).split(\"</span>\")[1].split('<div class=\"review-link')[0] for r in reviews]\n",
    "\n",
    "# printing the first 10 reviews\n",
    "reviews_text[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now you can do some interesting analyses on the reviews, e.g. find how many people complain about memory, storage space, built-in camera etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Practice problem: Scraping amazon.in to get shoe price data \n",
    "import pprint\n",
    "\n",
    "url = \"https://www.amazon.in/s/ref=nb_sb_noss?url=search-alias%3Daps&field-keywords=sport+shoes\"\n",
    "req = requests.get(url)\n",
    "\n",
    "# create a bs4 object\n",
    "# To avoid warnings, provide \"html5lib\" explicitly\n",
    "soup = bs4.BeautifulSoup(req.text, \"html5lib\")\n",
    "\n",
    "# get shoe names\n",
    "# shoe_data = soup.select('.a-size-medium')\n",
    "# shoe_data = soup.select('.a-size-small.a-link-normal.a-text-normal')\n",
    "# print(len(shoe_data))\n",
    "# print(pprint.pprint(shoe_data))\n",
    "\n",
    "# get shoe prices\n",
    "shoe_prices = soup.select('.a-price-whole')\n",
    "print(len(shoe_prices))\n",
    "pprint.pprint(shoe_prices)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
